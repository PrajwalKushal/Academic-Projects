{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "833f68a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of symbols in vocabulary: 59940\n",
      "HAM MESSAGES:\n",
      "   label                                               text\n",
      "0   ham                      Ok lar... Joking wif u oni...\n",
      "2   ham  U dun say so early hor... U c already then say...\n",
      "3   ham  Nah I don't think he goes to usf, he lives aro...\n",
      "5   ham  Even my brother is not like to speak with me. ...\n",
      "6   ham  As per your request 'Melle Melle (Oru Minnamin...\n",
      "\n",
      "SPAM MESSAGES:\n",
      "    label                                               text\n",
      "1   spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "4   spam  FreeMsg Hey there darling it's been 3 week's n...\n",
      "7   spam  WINNER!! As a valued network customer you have...\n",
      "8   spam  Had your mobile 11 months or more? U R entitle...\n",
      "10  spam  SIX chances to win CASH! From 100 to 20,000 po...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_12140\\763656480.py:43: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  sms_data['text'] = sms_data['text'].str.replace('[^a-zA-Z0-9\\s]', '')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      " [[4805   19]\n",
      " [  28  719]]\n",
      "Accuracy: 0.9915634535989948\n",
      "Precision: 0.9742547425474255\n",
      "Recall: 0.9625167336010709\n",
      "F1-score: 0.9683501683501684\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score,confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Load SMS spam dataset\n",
    "sms_data = pd.read_csv('SMSSpamCollection.csv', encoding='ISO-8859-1')\n",
    "sms_data.columns = ['label', 'text']\n",
    "\n",
    "# Get the vocabulary and its length\n",
    "vocabulary = vectorizer.vocabulary_\n",
    "total_symbols = len(vocabulary)\n",
    "\n",
    "print(\"Total number of symbols in vocabulary:\", total_symbols)\n",
    "\n",
    "# Split the data into ham and spam dataframes\n",
    "ham_data = sms_data[sms_data['label'] == 'ham']\n",
    "spam_data = sms_data[sms_data['label'] == 'spam']\n",
    "\n",
    "# Print the first few rows of each dataframe to verify\n",
    "print(\"HAM MESSAGES:\\n\", ham_data.head())\n",
    "print(\"\\nSPAM MESSAGES:\\n\", spam_data.head())\n",
    "\n",
    "# Split the ham_data into training and testing datasets\n",
    "train_data, test_data = train_test_split(ham_data, test_size=0.4, random_state=42)\n",
    "\n",
    "# Split the spam_data into training and testing datasets\n",
    "train_data, test_data = train_test_split(spam_data, test_size=0.4, random_state=42)\n",
    "\n",
    "# Combine the ham and spam training datasets\n",
    "train_data = pd.concat([ham_data, spam_data], axis=0)\n",
    "\n",
    "# Combine the ham and spam testing datasets\n",
    "test_data = pd.concat([ham_data, spam_data], axis=0)\n",
    "\n",
    "\n",
    "# Preprocess text data\n",
    "sms_data['text'] = sms_data['text'].str.lower()\n",
    "sms_data['text'] = sms_data['text'].str.replace('[^a-zA-Z0-9\\s]', '')\n",
    "sms_data['text'] = sms_data['text'].str.strip()\n",
    "\n",
    "# Extract character n-gram features from text data\n",
    "vectorizer = CountVectorizer(ngram_range=(2,4), analyzer='char')\n",
    "X_train_features = vectorizer.fit_transform(train_data['text'])\n",
    "X_test_features = vectorizer.transform(test_data['text'])\n",
    "\n",
    "# Train a Naive Bayes classifier on the training set\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train_features, train_data['label'])\n",
    "\n",
    "# Extract features from test data using the same CountVectorizer object\n",
    "test_counts = vectorizer.transform(test_data['text'])\n",
    "\n",
    "# Predict labels on the test set\n",
    "y_pred = clf.predict(test_counts)\n",
    "\n",
    "# Compute the confusion matrix\n",
    "confusion = confusion_matrix(test_data['label'], y_pred)\n",
    "\n",
    "# Evaluate the performance of the classifier\n",
    "accuracy = accuracy_score(test_data['label'], y_pred)\n",
    "precision = precision_score(test_data['label'], y_pred, pos_label='spam')\n",
    "recall = recall_score(test_data['label'], y_pred, pos_label='spam')\n",
    "f1 = f1_score(test_data['label'], y_pred, pos_label='spam')\n",
    "\n",
    "print('Confusion matrix:\\n', confusion)\n",
    "print('Accuracy:', accuracy)\n",
    "print('Precision:', precision)\n",
    "print('Recall:', recall)\n",
    "print('F1-score:', f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0f80f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70bf8221",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
