{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73f73ba3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification accuracy: 0.5558555855585559\n",
      "Confusion matrix:\n",
      " [[ 870    0    3    5    2    5   31    1   35   28]\n",
      " [   0 1079    2    1    0    0   10    0   38    5]\n",
      " [  79   25  266   91    5    2  269    4  271   20]\n",
      " [  32   39    6  353    2    3   51    8  409  107]\n",
      " [  19    2    5    4  168    7   63    7  210  497]\n",
      " [  71   25    1   20    3   44   40    2  586  100]\n",
      " [  12   12    3    1    1    7  895    0   26    1]\n",
      " [   0   15    2   10    5    1    5  280   39  670]\n",
      " [  13   72    3    7    3   11   12    4  648  201]\n",
      " [   5    7    3    6    1    0    1   13   18  955]]\n",
      "Precision score: 0.6865108998951719\n",
      "Recall score: 0.5484735723231241\n",
      "f1_score: 0.6666666666666666\n",
      "Macro average precision: 0.6865108998951719\n",
      "Macro average recall: 0.5484735723231241\n",
      "Macro average f1_score: 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score\n",
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Load the training data\n",
    "train_data = pd.read_csv(\"mnist_train.csv\")\n",
    "X_train = train_data.iloc[:, 1:].values\n",
    "y_train = train_data.iloc[:, 0].values\n",
    "\n",
    "# Load the test data\n",
    "test_data = pd.read_csv(\"mnist_test.csv\")\n",
    "X_test = test_data.iloc[:, 1:].values\n",
    "y_test = test_data.iloc[:, 0].values\n",
    "\n",
    "\n",
    "# Train the Gaussian Naive Bayes classifier\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels of the test set\n",
    "y_pred = gnb.predict(X_test)\n",
    "\n",
    "# Calculate the classification accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Classification accuracy:\", accuracy)\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Calculate the precision and recall scores\n",
    "precision = precision_score(y_test, y_pred, average=\"macro\")\n",
    "recall = recall_score(y_test, y_pred, average=\"macro\")\n",
    "\n",
    "# y_true is the true label, y_pred is the predicted label\n",
    "y_true = [1, 0, 1, 0, 1, 0]\n",
    "y_pred = [0, 0, 1, 0, 1, 1]\n",
    "\n",
    "# y_true is the true label, y_pred is the predicted label\n",
    "f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "\n",
    "# Print the confusion matrix, precision, and recall\n",
    "print(\"Confusion matrix:\\n\", cm)\n",
    "print(\"Precision score:\", precision)\n",
    "print(\"Recall score:\", recall)\n",
    "print(\"f1_score:\", f1)\n",
    "\n",
    "# Define the classifier object\n",
    "clf = GaussianNB()\n",
    "\n",
    "# Fit the classifier on the training data\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Calculate precision and recall for each class\n",
    "y_pred = clf.predict(X_test)\n",
    "precision = precision_score(y_test, y_pred, average=None)\n",
    "recall = recall_score(y_test, y_pred, average=None)\n",
    "\n",
    "# Calculate macro average precision and recall\n",
    "macro_precision = precision_score(y_test, y_pred, average='macro')\n",
    "macro_recall = recall_score(y_test, y_pred, average='macro')\n",
    "\n",
    "# y_true is the true label, y_pred is the predicted label\n",
    "y_test = [1, 0, 1, 0, 1, 0]\n",
    "y_pred = [0, 0, 1, 0, 1, 1]\n",
    "\n",
    "# y_true is the true label, y_pred is the predicted label\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "print(\"Macro average precision:\", macro_precision)\n",
    "print(\"Macro average recall:\", macro_recall)\n",
    "print(\"Macro average f1_score:\", f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9b7fcf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0ef6c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee8deda",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
